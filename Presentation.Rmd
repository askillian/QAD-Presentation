---
title: "Presentation QAD"
author: "Fabian Oberreiter, Konrad Medicus, Tobias Hilgart"
date: "24 4 2019"
output:
  ioslides_presentation:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(qad)
```

# Introduction

## What is a Copula?
A simple (implicit) definition of a Copula is as follows:

The joint distribution of two -- on $[0,1]$ -- continous random variables, restricted to $[0,1]^2$

This implies the following two properties, which are also used to define two-dimensional Copulae explicitly:

A function $A:[0,1]^2 \to [0,1]$ with the following properties:

1. $\forall u \in [0,1]: A(u,1) = A(1,u) = u, A(u,0) = A(0,u) = 0$

2. For  $0 \leq u_1 \leq u_2 \leq 1$ and $0 \leq v_1 \leq v_2 \leq 1$ we have:
    $A(u_2,v_2) - A(u_1,v_2) - A(u_2,v_1) + A(u_1,v_1) \geq 0$

    
## Examples of Copulae
* $M(u,v) = \text{min}\{u,v\}$
* $W(u,v) = \text{max}\{u+v-1,0\}$
* $\Pi(u,v) = u \cdot v$

Recall from your statistics course: For independent random variables, the joint distribution is the product of the boundary ones.

## Copulae - the Sklar theorem:
Let $H$ denote the joint distribution of the random variables $X,Y$. Furhermore, let $X \sim F$ and $Y \sim G$. Then, there exists a Copula $A$, such that for all $x,y \in \mathbb{R}$ we have:
$$ H(x,y) = A(F(x),G(y)) $$
For continuous $F,G$, the Copula $A$ is unique.
On the other hand, for every Copula $A$, we get a two-dimensional distribution via $A(F,G)$.

So, (two-dimensional) Copulae give us the link between two-dimensional distributions and their boundary-distributions.


## Empirical Copulae
Given a sample, how would you estimate the underlying distribution if, say, the sample size is sufficiently large?

We can (try to) do the same with Copulae, since the Sklar theorem at least gives us the existencce of a Copula $A_n$ i.e. $H_n(x,y) = A_n(F_n(x),G_n(y))$.

However, depending on the metric used, we will not get convergence just like that.

## Checkerbord Copulae:
An expedient for this problem is to mollify/aggregate, which leads to checkerbord copulae:

## Example

```{r,echo=FALSE,warning=FALSE}
X = data.frame(x = rnorm(100),y = rnorm(100))
cop = emp_c_copula(X,smoothing = TRUE,resolution = 100)
plot_density(cop)
```



## emp_c_copula
The function computes the mass-distribution of the empirical (checkerboard) copula, given a bivariate sample $(x_1,y_1),\dots,(x_n,y_n)$.

function: emp_c_copula($X$,smoothing,resolution)

Arguments:

* $X$: a dataframe with two columns, which contains the bivariate sample. Each row corresponds to one observation

* smoothing: a logical indicating, whether the checkerboard copula is computed. (default = TRUE)

* resolution: an integer indicating the number of vertical/horizontal strips of the checkerboard copula.


## emp_c_copula_eval
Via emp_c_copula_eval($X$,$u$,smoothing,resolution), you can directly evaluate the copula at the designated points $u$

## Example

```{r, message=FALSE}
#install.packages("qad")
library(qad)
```

```{r}
n = 200
X = data.frame(x1 = runif(n,0,1), x2 = runif(n,0,1))

emp_cop = emp_c_copula(X,smoothing = FALSE)
emp_check_cop = emp_c_copula(X,smoothing = TRUE,resolution = 20)
```




## Exercise 1

We want to check, whether the checkerboard copula can really estimate the "true" one. For that, take two independent random variables -- so you know, that the copula for the joint distribution is the product copula.

To get, how the density of the product copula looks, recall the PIT (Probability Integral Transform): For $X \sim F$ and $F$ cont., $F(X)$ has uniform distribution.

# The function plot_density:

# Dependence Measure $\zeta_1$

## Motivation

So, Copulae give us information of the dependency between $X$ and $Y$: If they are independent (i.e. information about $X$ does not give us any about $Y$ and vice versa), we already established, that the product Copula $\Pi$ describes exactly that.

On the other hand we could have complete dependence, i.e. knowing $X$ we pretty much know $Y$. Such a property should be reflected in the Copula and we want to use this to construct a *dependence measure*

## The one to measure them all:

A couple of math later, we define said depencence measure for a Copula $A$ to be
$$ \zeta_1(A) := 3 D_1(A,\Pi) \; \in [0,1] $$
where $\Pi$ is the product Copula and $D_1$ is a metric for Copulae. As it's construction involves markov kernels, we make do without discussing $D_1$ in detail.

We now compare a Copula to $\Pi$, to "complete randomness" so to say. Indeed, in accordance to our intuition, completely dependent Copulae have the highest dependence measure $1$, while $\Pi$ itself has dependence measure $0$.

## That's nice chap, but what do I do?

Now, we have a sample $(x_1,y_1), \dots, (x_n, y_n)$ and we would like to know "a" degree of dependency between the underlying RV-s $X$ and $Y$.

But wait, we already know how to estimate the copula $A$, that describes the distribution $F_{(X,Y)}$ and that is the empirical (checkerboard) copula!

We note, that the "plain" empirical copula might not neccisarily converge to the "true" one in the $D_1$ metric, where the empirical checkerboard does, so lucky us!

## That means:

So, we calculate the empirical checkerboard copula $A_n$ -- for sufficiently large sample size $n$ a good estimate for $A$. Then we simply estimate the dependency between $X$ and $Y$ as $\zeta_1(A_n)$

That seems like quite a bit of work to do all that by hand, now if only there was a R-function that would spare us the hassle...

## The function qad: What we do
*qad(df, resolution, permutation)* or

*qad(x,y, resolution, permutation)*;

Arguments:

* df or x,y: either two vectors x,y or a dataframe containing them, our sample;

* resolution: the resolution of the empirical checkerboard copula we need to calculate,
  NULL uses the optimal resolution by default;
  
* permutation: whether a permutated p-value is to be constructed default = FALSE.

## The function qad: What we do

* nperm: the number of permutation runs

* DoParallel: whether the permutation test is computed in parallel

* ncores: the number of cores used for parallel calculation. By default (=NULL), uses
  max(cores)-1
  
* print: whether the result is printed to the console

## The function qad: What we get:


